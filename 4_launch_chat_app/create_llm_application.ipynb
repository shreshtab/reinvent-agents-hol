{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated App Deployment with CML APIv2\n",
    "Use this Notebook after you have explored Bedrock, Pinecone and CrewAI to deploy your Chat app in Cloudera AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Import variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cmlapi\n",
    "import random\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Get CML API Client and list the available Runtimes\n",
    "This code connects to your Cloudera Machine Learning (CML) environment, retrieves a list of available Python 3.10 runtimes with Nvidia GPU support and JupyterLab as the editor, prints the list, and then selects and stores the image identifier of the second runtime in the list. It also sets an environment variable APP_IMAGE_ML_RUNTIME with this image identifier for future use in launching jobs within the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'next_page_token': '',\n",
      " 'runtimes': [{'description': 'Standard edition JupyterLab Python runtime '\n",
      "                              'provided by Cloudera',\n",
      "               'edition': 'Standard',\n",
      "               'editor': 'JupyterLab',\n",
      "               'full_version': '2024.10.1-b12',\n",
      "               'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-standard:2024.10.1-b12',\n",
      "               'kernel': 'Python 3.10',\n",
      "               'register_user_id': 0,\n",
      "               'status': 'ENABLED'}]}\n",
      "{'description': 'Standard edition JupyterLab Python runtime provided by '\n",
      "                'Cloudera',\n",
      " 'edition': 'Standard',\n",
      " 'editor': 'JupyterLab',\n",
      " 'full_version': '2024.10.1-b12',\n",
      " 'image_identifier': 'docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-standard:2024.10.1-b12',\n",
      " 'kernel': 'Python 3.10',\n",
      " 'register_user_id': 0,\n",
      " 'status': 'ENABLED'}\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.10-standard:2024.10.1-b12\n"
     ]
    }
   ],
   "source": [
    "client = cmlapi.default_client(url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"), cml_api_key=os.getenv(\"CDSW_APIV2_KEY\"))\n",
    "available_runtimes = client.list_runtimes(search_filter=json.dumps({\n",
    "    \"kernel\": \"Python 3.10\",\n",
    "    \"edition\": \"Standard\",\n",
    "    \"editor\": \"JupyterLab\",\n",
    "    \"full_version\": \"2024.10.1-b12\"\n",
    "}))\n",
    "print(available_runtimes)\n",
    "\n",
    "# Set available runtimes to the latest runtime in the environment (iterator is the number that begins with 0 and advances sequentially)\n",
    "# The JOB_IMAGE_ML_RUNTIME variable stores the ML Runtime which will be used to launch the job\n",
    "print(available_runtimes.runtimes[0])\n",
    "print(available_runtimes.runtimes[0].image_identifier)\n",
    "APP_IMAGE_ML_RUNTIME = available_runtimes.runtimes[0].image_identifier\n",
    "\n",
    "## Store the ML Runtime for any future jobs in an environment variable so we don't have to do this step again\n",
    "os.environ['APP_IMAGE_ML_RUNTIME'] = APP_IMAGE_ML_RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Get the current working project\n",
    "Here we get the current project from the environment variable \"CDSW Project ID\" and print its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2024, 11, 22, 23, 24, 27, 649274, tzinfo=tzlocal()),\n",
      " 'creation_status': 'success',\n",
      " 'creator': {'email': 'sbalachandar@cloudera.com',\n",
      "             'name': 'Shreshta Balachandar',\n",
      "             'username': 'sbalachandar'},\n",
      " 'default_engine_type': 'ml_runtime',\n",
      " 'description': '',\n",
      " 'environment': '{\"CDSW_APP_POLLING_ENDPOINT\":\"/\",\"PROJECT_OWNER\":\"sbalachandar\"}',\n",
      " 'ephemeral_storage_limit': 30,\n",
      " 'ephemeral_storage_request': 0,\n",
      " 'id': 'xd1j-uzqr-043d-m60m',\n",
      " 'name': 'Cloudera Agentic AI',\n",
      " 'owner': {'email': 'sbalachandar@cloudera.com',\n",
      "           'name': 'Shreshta Balachandar',\n",
      "           'username': 'sbalachandar'},\n",
      " 'permissions': {'admin': True,\n",
      "                 'business_user': True,\n",
      "                 'inherit': False,\n",
      "                 'operator': True,\n",
      "                 'read': True,\n",
      "                 'write': True},\n",
      " 'shared_memory_limit': 0,\n",
      " 'updated_at': datetime.datetime(2024, 11, 25, 19, 58, 3, 17220, tzinfo=tzlocal()),\n",
      " 'visibility': 'private'}\n"
     ]
    }
   ],
   "source": [
    "project = client.get_project(project_id=os.getenv(\"CDSW_PROJECT_ID\"))\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Create and Run Application for Hosted LLM Application\n",
    "This code creates a Cloudera Machine Learning (CML) application with the name \"CML LLM Gradio Interface\" and a description, associates it with a specific project (project.id), assigns it a subdomain, specifies Python 3 as the kernel, and provides a script path for the application. It also sets resource specifications for CPU and memory and assigns the runtime identifier obtained from the environment variable APP_IMAGE_ML_RUNTIME. Finally, it creates the application within the specified project using the client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT EXECUTE UNTIL YOU SET A UNIQUE SUBDOMAIN\n",
    "application_request = cmlapi.CreateApplicationRequest(\n",
    "     name = \"Agentic AI Chat Interface\",\n",
    "     description = \"Hosted interface for the CML LLM Gradio UI\",\n",
    "     project_id = project.id,\n",
    "     subdomain = \"agentic-ai-chat-123\", # THIS MUST BE UNIQUE PER USER\n",
    "     script = \"chat_app/agents_app_launch.py\",\n",
    "     cpu = 1,\n",
    "     memory = 4,\n",
    "     runtime_identifier = os.getenv('APP_IMAGE_ML_RUNTIME')\n",
    ")\n",
    "\n",
    "app = client.create_application(\n",
    "     project_id = project.id,\n",
    "     body = application_request\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
