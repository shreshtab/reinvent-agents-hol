{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Working With Pinecone Vector Database\n",
    "Although Vector Databases have existed long before Large Language Models, vector DBs have become an important part of many LLM solutions. In particular, Retreival Augmented Generation (or RAG) architecture addresses LLM's halucinations and issues with longer-term memory by augmenting the user's prompt with the results of a search accross a vector DB. [Pinecone](https://www.pinecone.io/) is a cloud-based vector database that is easy to integrate with your Cloudera AI workflow, as this notebook shows. \n",
    "\n",
    "We pre-loaded the Pinecone Vector DB using Cloudera AI's Jobs feature that scraped a few sample policies, cleaned up the HTML tags and loaded each page into Pinecone. This notebook will focus on interacting with Pinecone from a Jupyter notebook.\n",
    "\n",
    "![Exercise 2 overview](../assets/exercise_2.png)\n",
    "\n",
    "### 2.1 Imports and global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBEDDING_MODEL_REPO = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_INDEX = os.getenv('PINECONE_INDEX')\n",
    "dimension = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Initialize Pinecone connection\n",
    "Pinecone client is initialized with the parameters defined previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising Pinecone connection...\n",
      "Pinecone initialised\n",
      "Getting 'ecss-docs' as object...\n",
      "Success\n",
      "Total number of embeddings in Pinecone index is 3.\n"
     ]
    }
   ],
   "source": [
    "print(\"initialising Pinecone connection...\")\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    \n",
    "print(\"Pinecone initialised\")\n",
    "\n",
    "print(f\"Getting '{PINECONE_INDEX}' as object...\")\n",
    "index = pc.Index(PINECONE_INDEX)\n",
    "print(\"Success\")\n",
    "\n",
    "# Get latest statistics from index\n",
    "current_collection_stats = index.describe_index_stats()\n",
    "print('Total number of embeddings in Pinecone index is {}.'.format(current_collection_stats.get('total_vector_count')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Function to peform the vector search \n",
    "The idea is to find a chunk from the Knowledge Base that is \"close\" to what the original user's prompt is. We perform a semantic search using the user's question, find the nearest knowledge base chunk, and return the content of that chunk along with its source and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for a user question and query Pinecone vector DB for nearest knowledge base chunk\n",
    "def get_nearest_chunk_from_pinecone_vectordb(index, question):\n",
    "    # Generate embedding for user question with embedding model\n",
    "    retriever = SentenceTransformer(EMBEDDING_MODEL_REPO)\n",
    "    xq = retriever.encode([question]).tolist()\n",
    "    xc = index.query(vector=xq, top_k=5,\n",
    "                 include_metadata=True)\n",
    "    \n",
    "    matching_files = []\n",
    "    scores = []\n",
    "    for match in xc['matches']:\n",
    "        # extract the 'file_path' within 'metadata'\n",
    "        file_path = match['metadata']['file_path']\n",
    "        # extract the individual scores for each vector\n",
    "        score = match['score']\n",
    "        scores.append(score)\n",
    "        matching_files.append(file_path)\n",
    "\n",
    "    # Return text of the nearest knowledge base chunk \n",
    "    # Note that this ONLY uses the first matching document for semantic search. matching_files holds the top results so you can increase this if desired.\n",
    "    response = load_context_chunk_from_data(matching_files[0])\n",
    "    sources = matching_files[0]\n",
    "    score = scores[0]\n",
    "    return response, sources, score\n",
    "\n",
    "# Return the Knowledge Base doc based on Knowledge Base ID (relative file path)\n",
    "def load_context_chunk_from_data(id_path):\n",
    "    with open(id_path, \"r\") as f: # Open file in read mode\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Examine the results of the vector search\n",
    "Given the text of the question, we can now perform a vector search and output the results in the notebook. An important detail here is the ability to interact with metadata (e.g. context source) which can be used to narrow down the search space and, more critically, for authorization. These approaches are out of scope of this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context Chunk: \n",
      "Return and Refund Policy Our Return and Refund Policy was last updated November 15th, 2024 Thank you for shopping at ECSS. If, for any reason, You are not completely satisfied with a purchase We invite You to review our policy on refunds and returns. This Return and Refund Policy was generated by TermsFeed Return and Refund Policy Template. The following terms are applicable for any products that You purchased with Us. Interpretation and Definitions Interpretation The words of which the initial letter is capitalized have meanings defined under the following conditions. The following definitions shall have the same meaning regardless of whether they appear in singular or in plural. Definitions For the purposes of this Return and Refund Policy:   \"Company\" (referred to as either \"the Company\", \"We\", \"Us\" or \"Our\" in this Agreement) refers to ECommerce Customer Service Squad (ECSS)   \"Goods\" refers to the items offered for sale on the Service.   \"Orders\" means a request by You to purchase Goods from Us.   \"Service\" refers to the Website.   \"Website\" refers to ECSS, accessible from https://www.ecss.com.br   \"You\" means the individual accessing or using the Service, or the company, or other legal entity on behalf of which such individual is accessing or using the Service, as applicable.   Your Order Cancellation Rights You are entitled to cancel Your Order within 14 days without giving any reason for doing so. The deadline for cancelling an Order is 14 days from the date on which You received the Goods or on which a third party you have appointed, who is not the carrier, takes possession of the product delivered. In order to exercise Your right of cancellation, You must inform Us of your decision by means of a clear statement. You can inform us of your decision by:  By visiting this page on our website: https://www.ecss.com.br/contactus By sending us an email: contactus@ecss.com.br  We will reimburse You no later than 14 days from the day on which We receive the returned Goods. We will use the same means of payment as You used for the Order, and You will not incur any fees for such reimbursement. Conditions for Returns In order for the Goods to be eligible for a return, please make sure that:  The Goods were purchased in the last 14 days The Goods are in the original packaging  The following Goods cannot be returned:  The supply of Goods made to Your specifications or clearly personalized. The supply of Goods which according to their nature are not suitable to be returned, deteriorate rapidly or where the date of expiry is over. The supply of Goods which are not suitable for return due to health protection or hygiene reasons and were unsealed after delivery. The supply of Goods which are, after delivery, according to their nature, inseparably mixed with other items.  We reserve the right to refuse returns of any merchandise that does not meet the above return conditions in our sole discretion. Returning Goods You are responsible for the cost and risk of returning the Goods to Us. You should send the Goods at the following address: PO Box 878, Sao Paulo, BR We cannot be held responsible for Goods damaged or lost in return shipment. Therefore, We recommend an insured and trackable mail service. We are unable to issue a refund without actual receipt of the Goods or proof of received return delivery. Gifts If the Goods were marked as a gift when purchased and then shipped directly to you, You'll receive a gift credit for the value of your return. Once the returned product is received, a gift certificate will be mailed to You. If the Goods weren't marked as a gift when purchased, or the gift giver had the Order shipped to themselves to give it to You later, We will send the refund to the gift giver. Contact Us If you have any questions about our Returns and Refunds Policy, please contact us:  By visiting this page on our website: https://www.ecss.com.br/contactus By sending us an email: contactus@ecss.com.br  \n",
      "\n",
      "Context Source(s): \n",
      "/home/cdsw/2_query_vector_db/parsed/return_policy.txt\n",
      "\n",
      "Pinecone Score: \n",
      "0.541406691\n"
     ]
    }
   ],
   "source": [
    "question = \"What is your return policy?\" ## (Swap with your own based on your dataset)\n",
    "\n",
    "context_chunk, sources, score = get_nearest_chunk_from_pinecone_vectordb(index, question)\n",
    "print(\"\\nContext Chunk: \")\n",
    "print(context_chunk)\n",
    "print(\"\\nContext Source(s): \")\n",
    "print(sources)\n",
    "print(\"\\nPinecone Score: \")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Takeaways\n",
    "* Vector search is a critical component of any LLM app using RAG architecture\n",
    "* Cloudera's partner [Pinecone](https://www.pinecone.io/) provides a convenient SaaS offering for a Vector Database to support LLM RAG architecture\n",
    "* Metadata from each entry in the Vector DB can be used to refine searches and add custom authorization frameworks\n",
    "\n",
    "### Up Next: Go to Exercise 3\n",
    "Where a gradio app is launched to complete the first iteration of the Q&A chat use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
